COIL: Revisit Exact Lexical Match in Information Retrievalwith Contextualized Inverted ListLuyu Gao, Zhuyun Dai, Jamie CallanLanguage Technologies InstituteCarnegie Mellon University{luyug, zhuyund, callan}@cs.cmu.eduAbstractClassical information retrieval systems such asBM25 rely on exact lexical match and carryout search efﬁciently with inverted list index.Recent neural IR models shifts towards softsemantic matching all query document terms,but they lose the computation efﬁciency ofexact match systems. This paper presentsCOIL, a contextualized exact match retrievalarchitecture that brings semantic lexical match-ing. COIL scoring is based on overlappingquery document tokens’ contextualized repre-sentations. The new architecture stores con-textualized token representations in invertedlists, bringing together the efﬁciency of exactmatch and the representation power of deeplanguage models. Our experimental resultsshow COIL outperforms classical lexical re-trievers and state-of-the-art deep LM retrieverswith similar or smaller latency.11 IntroductionWidely used, bag-of-words (BOW) information re-trieval (IR) systems such as BM25 rely on exactlexical match2between query and document terms.Recent study in neural IR takes a different approachand compute soft matching between all query anddocument terms to model complex matching.The shift to soft matching in neural IR modelsattempts to address vocabulary mismatch problems,that query and the relevant documents use differ-ent terms, e.g. cat v.s. kitty, for the same con-cept (Huang et al., 2013; Guo et al., 2016; Xionget al., 2017). Later introduction of contextualizedrepresentations (Peters et al., 2018) from deep lan-guage models (LM) further address semantic mis-match , that the same term can refer to differentconcepts, e.g., bank of river vs. bank in ﬁnance.Fine-tuned deep LM rerankers produce token rep-resentations based on context and achieve state-of-1Our code is available at https://github.com/luyug/COIL .2Exact match up to morphological changes.the-art in text ranking with huge performance leap(Nogueira and Cho, 2019; Dai and Callan, 2019b).Though the idea of soft matching all tokens iscarried through the development of neural IR mod-els, seeing the success brought by deep LMs, wetake a step back and ask: how much gain can we getif we introduce contextualized representations backto lexical exact match systems? In other words, canwe build a system that still performs exact query-document token matching but compute matchingsignals with contextualized token representationsinstead of heuristics? This may seem a constrainton the model, but exact lexical match produce moreexplainable and controlled patterns than soft match-ing. It also allows search to focus on only thesubset of documents that have overlapping termswith query, which can be done efﬁciently with in-verted list index. Meanwhile, using dense contex-tualized token representations enables the modelto handle semantic mismatch, which has been along-standing problem in classic lexical systems.To answer the question, we propose a new lexi-cal matching scheme that uses vector similaritiesbetween query-document overlapping term contex-tualized representations to replace heuristic scor-ing used in classical systems. We present COn-textualized Inverted List (COIL), a new exact lex-ical match retrieval architecture armed with deepLM representations. COIL processes documentswith deep LM ofﬂine and produces representationsfor each document token. The representations aregrouped by their surface tokens into inverted lists.At search time, we build representation vectorsfor query tokens and perform contextualized ex-act match: use each query token to look up itsown inverted list and compute vector similaritywith document vectors stored in the inverted listas matching scores. COIL enables efﬁcient searchwith rich-in-semantic matching between query anddocument.Our contributions include 1) introduce a novelarXiv:2104.07186v1  [cs.IR]  15 Apr 2021retrieval architecture, contextualized invertedlists (COIL) that brings semantic matching intolexical IR systems, 2) show matching signals in-duced from exact lexical match can capture com-plicated matching patterns, 3) demonstrate COILsigniﬁcantly outperform classical and deep LMaugmented lexical retrievers as well as state-of-the-art dense retrievers on two retrieval tasks.2 Related WorkLexical Retriever Classical IR systems rely onexact lexical match retrievers such as BooleanRetrieval, BM25 (Robertson and Walker, 1994)and statistical language models (Lafferty and Zhai,2001). This type of retrieval model can processqueries very quickly by organizing the documentsinto inverted index, where each distinct term hasan inverted list that stores information about docu-ments it appears in. Nowadays, they are still widelyused in production systems. However, these re-trieval models fall short of matching related terms(vocabulary mismatch) or modeling context of theterms (semantic mismatch). Much early effortwas put into improving exact lexical match retriev-ers, such as matching n-grams (Metzler and Croft,2005) or expanding queries with terms from relateddocuments (Lavrenko and Croft, 2001). However,these methods still use BOW framework and havelimited capability of modeling human languages.Neural Ranker In order to deal with vocab-ulary mismatch, neural retrievers that rely onsoft matching between numerical text represen-tations are introduced. Early attempts computesimilarity between pre-trained word embeddingsuch as word2vec (Mikolov et al., 2013) andGLoVe (Pennington et al., 2014) to produce match-ing score (Ganguly et al., 2015; Diaz et al., 2016).One more recent approach encodes query and doc-ument each into a vector and computes vector sim-ilarity (Huang et al., 2013). Later researches real-ized the limited capacity of a single vector to en-code ﬁne-grained information and introduced fullinteraction models to perform soft matching be-tween all term vectors (Guo et al., 2016; Xionget al., 2017). In these approaches, scoring isbased on learned neural networks and the hugelyincreased computation cost limited their use toreranking a top candidate list generated by a lexicalretriever.Deep LM Based Ranker and Retriever DeepLM made a huge impact on neural IR. Fine-tuned Transformer (Vaswani et al., 2017) LMBERT (Devlin et al., 2019) achieved state-of-the-art reranking performance for passages and docu-ments (Nogueira and Cho, 2019; Dai and Callan,2019b). As illustrated in Figure 1a, the commonapproach is to feed the concatenated query docu-ment text through BERT and use BERT’s [CLS]output token to produce a relevance score. Thedeep LM rerankers addressed both vocabulary andsemantic mismatch by computing full cross atten-tion between contextualized token representations.Lighter deep LM rankers are developed (MacA-vaney et al., 2020; Gao et al., 2020), but their crossattention operations are still too expensive for full-collection retrieval.Later research therefore resorted to augment-ing lexical retrieval with deep LMs by expandingthe document surface form to narrow the vocab-ulary gap, e.g., DocT5Query (Nogueira and Lin,2019), or altering term weights to emphasize impor-tant terms, e.g., DeepCT (Dai and Callan, 2019a).Smartly combining deep LM retriever and rerankercan offer additive gain for end performance (Gaoet al., 2021a). These retrievers however still sufferfrom vocabulary and semantic mismatch as tradi-tional lexical retrievers.Another line of research continues the work onsingle vector representation and build dense retriev-ers, as illustrated in Figure 1b. They store docu-ment vectors in a dense index and retrieve themthrough Nearest Neighbours search. Using deepLMs, dense retrievers have achieved promising re-sults on several retrieval tasks (Karpukhin et al.,2020). Later researches show that dense retrievalsystems can be further improved by better train-ing (Xiong et al., 2020; Gao et al., 2021b).Single vector systems have also been extendedto multi-vector representation systems. Poly-encoder (Humeau et al., 2020) encodes queriesinto a set of vectors. Similarly, Me-BERT (Luanet al., 2020) represents documents with a set of vec-tors. A concurrent work ColBERT (Figure 1c) usemultiple vectors to encode both queries and docu-ments (Khattab and Zaharia, 2020). In particular, itrepresents a documents with all its terms’ vectorsand a query with an expanded set of term vectors.It then computes all-to-all (Cartesian) soft matchbetween the tokens. ColBERT performs interactionas dot product followed pooling operations, whichCLS bank account SEP bank river bankCLS bank account SEP bank river bankCLS bank account SEP bank river bankCLS bank account SEP bank river bankscore(a) Cross-Attention Model (e.g., BERT reranker)CLS bank account CLS bank river bankCLS bank accountCLS bank accountCLS bank river bankCLS bank river bankscore (b) Dense Retrievers (e.g., DPR)CLS bank account CLS bank river bankCLS bank accountCLS bank accountCLS bank river bankCLS bank river bankEXP EXPscoremax max maxEXPEXPEXPEXPmax max(c) ColBERT: All-to-All MatchCLS bank account CLS bank river bankCLS bank accountCLS bank accountCLS bank river bankCLS bank river bankdot maxsum (d) COIL: Contextualized Exact MatchFigure 1: An illustration of reranking/retrieval mechanisms with deep LM, including our proposed model, COIL.BankRiverAccountBankAccountTraditional Inverted Lists Querydocid: 3tf: 2docid: 9tf: 1docid: 1tf: 1docid: 2tf: 1docid: 4tf: 1docid: 5tf: 2docid: 1tf: 1docid: 3tf: 1docid: 6tf: 1........BM25 scoringBM25 scoringBM25 scoringFigure 2: An illustration of traditional inverted lists.The inverted list maps a term to the list of documentswhere the term occurs. Retriever looks up query terms’inverted lists and scores those documents with storedstatistics such as term frequency (tf).allows it to also leverage a dense index to do fullcorpus retrieval. However, since ColBERT encodesa document with all tokens, it adds another orderof magnitude of index complexity to all aforemen-tioned methods: document tokens in the collectionneed to be stored in a single huge index and con-sidered at query time. Consequently, ColBERT isengineering and hardware demanding.3 MethodologiesIn this section, we ﬁrst provide some preliminarieson exact lexical match systems. Then we discussCOIL’s contextualized exact match design and howits search index is organized. We also give a com-parison between COIL and other popular retrievers.BankRiverAccountBankAccountContextualized Inverted Lists Querydocid  [1 3 6 7]docid  [1 2 4 5 5 9]docid  [3 3 9]vectorsvectorsvectorsCLSdocid  [1 2 3 4 .............C]vectors ...CLSmatrixproductmatrixproductmatrixproductFigure 3: COIL’s index and retrieval architecture.COIL-tok relies on the exact token matching (lower).COIL-full includes in addition CLS matching (upper).3.1 PreliminariesClassic lexical retrieval system relies on overlap-ping query document terms under morphologicalgeneralization like stemming, in other words, exactlexical match , to score query document pair. Ascoring function is deﬁned as a sum of matchedterm scores. The scores are usually based on statis-tics like term frequency ( tf). Generally, we canwrite,s=Xt2q\dt(hq(q;t);hd(d;t)) (1)where for each overlapping term tbetween query qand document d, functionshqandhdextract terminformation and a term scoring function tcom-bines them. A popular example is BM25, whichcomputes,sBM25 =Xt2q\didf(t)hBM25q(q;t)hBM25d(d;t)hBM25q(q;t) =tft;q(1 +k2)tft;q+k2hBM25d(d;t) =tft;d(1 +k1)tft;d+k1(1 b+bjdjavgdl)(2)wheretft;drefers to term frequency of term tindocumentd,tft;qrefers to the term frequency inquery,idf(t)is inverse document frequency, and b,k1,k2are hyper-parameters.One key advantage of exact lexical match sys-tems lies in efﬁciency. With summation over exactmatches, scoring of each query term only goes todocuments that contain matching terms. This canbe done efﬁciently using inverted list indexing (Fig-ure 2). The inverted list maps back from a termto a list of documents where the term occurs. Tocompute Equation 1, the retriever only needs totraverse the subset of documents in query terms’inverted lists instead of going over the entire docu-ment collection.While recent neural IR research mainly focuseson breaking the exact match bottleneck with softmatching of text, we hypothesize that exact matchitself can be improved by replacing semantic in-dependent frequency-based scoring with semanticrich scoring. In the rest of this section, we showhow to modify the exact lexical match frameworkwith contextualized term representations to buildeffective and efﬁcient retrieval systems.3.2 Contextualized Exact Lexical MatchInstead of term frequency, we desire to encodethe semantics of terms to facilitate more effectivematching. Inspired by recent advancements in deepLM, we encode both query and document tokensinto contextualized vector representations and carryout matching between exact lexical matched tokens.Figure 1d illustrates the scoring model of COIL.In this work, we use a Transformer languagemodel3as the contextualization function. We en-code a query qwith the language model (LM) andrepresent its i-th token by projecting the corre-sponding output:vqi=WtokLM(q;i) +btok (3)3We used the base, uncased variant of BERT.where Wntnlmtokis a matrix that maps the LM’snlmdimension output into a vector of lower di-mensionnt. We down project the vectors as wehypothesize that it sufﬁces to use lower dimensiontoken vectors. We conﬁrm this in section 5. Simi-larly, we encode a document d’sj-th tokendjwith:vdj=WtokLM(d;j) +btok (4)We then deﬁne the contextualized exact lexicalmatch scoring function between query documentbased on vector similarities between exact matchedquery document token pairs:stok(q;d) =Xqi2q\dmaxdj=qi(vqi|vdj) (5)Note that, importantly, the summation goes throughonly overlapping terms, qi2q\d. For each querytokenqi, we ﬁnds all same tokensdjin the docu-ment, computes their similarity with qiusing thecontextualized token vectors. The maximum sim-ilarities are picked for query token qi. Max op-erator is adopted to capture the most importantsignal (Kim, 2014). This ﬁts in the general lexicalmatch formulation, with hqgiving representationforqi,htgiving representations for all dj=qi, andtcompute dot similarities between query vectorwith document vectors and max pool the scores.As with classic lexical systems, stokdeﬁned inEquation 5 does not take into account similaritiesbetween lexical-different terms, thus faces vocabu-lary mismatch. Many popular LMs (Devlin et al.,2019; Yang et al., 2019; Liu et al., 2019) use aspecial CLS token to aggregate sequence represen-tation. We project the CLS vectos with Wncnlmclsto represent the entire query or document,vqcls=WclsLM(q;CLS) +bclsvdcls=WclsLM(d;CLS) +bcls(6)The similarity between vqclsandvdclsprovides high-level semantic matching and mitigates the issue ofvocabulary mismatch. The full form of COIL is:sfull(q;d) =stok(q;d) +vqcls|vdcls (7)In the rest of the paper, we refer to systems withCLS matching COIL-full and without COIL-tok .COIL’s scoring model (Figure 1d) is fully differ-entiable. Following earlier work (Karpukhin et al.,2020), we train COIL with negative log likelihooddeﬁned over query q, a positive document d+and aset of negative documents fd 1;d 2;::d l::gas loss.L= logexp(s(q;d+))exp(s(q;d+)) +Plexp(s(q;d l))(8)Following Karpukhin et al. (2020), we use in batchnegatives and hard negatives generated by BM25.Details are discussed in implementation, section 4.3.3 Index and Retrieval with COILCOIL pre-computes the document representationsand builds up a search index, which is illustrated inFigure 3. Documents in the collection are encodedofﬂine into token and CLS vectors. Formally, fora unique token tin the vocabulary V, we collectits contextualized vectors from all of its mentionsfrom documents in collection C, building token t’scontextualized inverted list:It=fvdjjdj=t;d2Cg; (9)where vdjis the BERT-based token encoding de-ﬁned in Equation 4. We deﬁne search index tostore inverted lists for all tokens in vocabulary,I=fItjt2Vg. For COIL-full, we also build anindex for the CLS token Icls=fvdclsjd2Cg.As shown in Figure 3, in this work we im-plement COIL’s by stacking vectors in each in-verted listItinto a matrix MntjIkj, so that sim-ilarity computation that traverses an inverted listand computes vector dot product can be done ef-ﬁciently as one matrix-vector product with opti-mized BLAS (Blackford et al., 2002) routines onCPU or GPU. All vdclsvectors can also be organizedin a similar fashion into matrix Mclsand queriedwith matrix product. The matrix implementationhere is an exhaustive approach that involves all vec-tors in an inverted list. As a collection of densevectors, it is also possible to organize each invertedlist as an approximate search index (Johnson et al.,2017; Guo et al., 2019) to further speed up search.When a query qcomes in, we encode every ofits token into vectors vqi. The vectors are sent tothe subset of COIL inverted lists that correspondsquery tokens J=fItjt2qg. where the matrixproduct described above is carried out. This isefﬁcient asjJj<<jIj, having only a small subsetof all inverted lists to be involved in search. ForCOIL-full, we also use encoded CLS vectors vqclsto query the CLS index to get the CLS matchingscores. The scoring over different inverted lists canserve in parallel. The scores are then combined byEquation 5 to rank the documents.Readers can ﬁnd detailed illustration ﬁgures inthe Appendix A, for index building and querying,Figure 4 and Figure 5, respectively.3.4 Connection to Other RetrieversDeep LM based Lexical Index Models likeDeepCT (Dai and Callan, 2019a, 2020) andDocT5Query (Nogueira and Lin, 2019) alter tft;din documents with deep LM BERT or T5. This issimilar to a COIL-tok with token dimension nt= 1.A single degree of freedom however measures moreof a term importance than semantic agreement .Dense Retriever Dense retrievers (Figure 1b)are equivalent to COIL-full’s CLS matching. COILmakes up for the lost token-level interactions indense retriever with exact matching signals.ColBERT ColBERT (Figure 1c) computes rel-evance by soft matching allquery and documentterm’s contextualized vectors.s(q;d) =Xqi2[cls;q;exp]maxdj2[cls;d](vqi|vdj) (10)where interactions happen among query q, docu-mentd,clsand set of query expansion tokens exp.The all-to-all match contrasts COIL that only usesexact match. It requires a dense retrieval over alldocument tokens’ representations as opposed toCOIL which only considers query’s overlapping to-kens, and are therefore much more computationallyexpensive than COIL.4 Experiment MethodologiesDatasets We experiment with two large scale adhoc retrieval benchmarks from the TREC 2019Deep Learning (DL) shared task: MSMARCOpassage (8M English passages of average lengtharound 60 tokens) and MSMARCO document (3MEnglish documents of average length around 900tokens)4. For each, we train models with theMSMARCO Train queries, and record results onMSMARCO Dev queries and TREC DL 2019test queries. We report mainly full-corpus re-trieval results but also include the rerank task onMSMARCO Dev queries where we use neuralscores to reorder BM25 retrieval results providedby MSMARO organizers. Ofﬁcial metrics include4Both datasets can be downloaded from https://microsoft.github.io/msmarco/MRR@1K and NDCG@10 on test and MRR@10on MSMARCO Dev. We also report recall for thedev queries following prior work (Dai and Callan,2019a; Nogueira and Lin, 2019).Compared Systems Baselines include 1) tradi-tional exact match system BM25, 2) deep LM aug-mented BM25 systems DeepCT (Dai and Callan,2019a) and DocT5Query (Nogueira and Lin, 2019),3) dense retrievers, and 4) soft all-to-all retrieverColBERT. For DeepCT and DocT5Query, we usethe rankings provided by the authors. For denseretrievers, we report two dense retrievers trainedwith BM25 negatives or with mixed BM25 andrandom negatives, published in Xiong et al. (2020).However since these systems use a robust versionof BERT, RoBERTa (Liu et al., 2019) as the LMand train document retriever also on MSMARCOpassage set, we in addition reproduce a third denseretriever, that uses the exact same training setup asCOIL. All dense retrievers use 768 dimension em-bedding. For ColBERT, we report its published re-sults (available only on passage collection). BERTreranker is added in the rerank task.We include 2 COIL systems: 1) COIL-tok, theexact token match only system, and 2) COLL-full,the model with both token match and CLS match.Implementation We build our models with Py-torch (Paszke et al., 2019) based on huggingfacetransformers (Wolf et al., 2019). COIL’s LM isbased on BERT’s base variant. COIL systems usetoken dimension nt= 32 and COIL-full use CLSdimensionnc= 768 as default, leading to 110Mparameters. We add a Layer Normalization to CLSvector when useful. All models are trained for 5epochs with AdamW optimizer, a learning rate of3e-6, 0.1 warm-up ratio, and linear learning ratedecay, which takes around 12 hours. Hard neg-atives are sampled from top 1000 BM25 results.Each query uses 1 positive and 7 hard negatives;each batch uses 8 queries on MSMARCO passageand 4 on MSMARCO document. Documents aretruncated to the ﬁrst 512 tokens to ﬁt in BERT.We conduct validation on randomly selected 512queries from corresponding train set. Latency num-bers are measured on dual Xeon E5-2630 v3 forCPU and RTX 2080 ti for GPU. We implementCOIL’s inverted lists as matrices as described insubsection 3.3, using NumPy (Harris et al., 2020)on CPU and Pytorch on GPU. We perform a) a setof matrix products to compute token similaritiesover contextualized inverted lists, b) scatter to maptoken scores back to documents, and c) sort to rankthe documents. Illustration can be found in theappendix, Figure 5.5 ResultsThis section studies the effectiveness of COILand how vector dimension in COIL affects theeffectiveness-efﬁciency tradeoff. We also providequalitative analysis on contextualized exact match.5.1 Main ResultsTable 1 reports various systems’ performance onthe MARCO passage collection. COIL-tok ex-act lexical match only system signiﬁcantly out-performs all previous lexical retrieval systems.With contextualized term similarities, COIL-tokachieves a MRR of 0.34 compared to BM25’s MRR0.18. DeepCT and DocT5Query, which also usedeep LMs like BERT and T5, are able to break thelimit of heuristic term frequencies but are still lim-ited by semantic mismatch issues. We see COIL-tok outperforms both systems by a large margin.COIL-tok also ranks top of the candidate list bet-ter than dense retrieves. It prevails in MRR andNDCG while performs on par in recall with thebest dense system, indicating that COIL’s tokenlevel interaction can improve precision. With theCLS matching added, COIL-full gains the abilityto handle mismatched vocabulary and enjoys an-other performance leap, outperforming all denseretrievers.COIL-full achieves a very narrow performancegap to ColBERT. Recall that ColBERT computesall-to-all soft matches between all token pairs. Forretrieval, it needs to consider for each query tokenallmentions of alltokens in the collection (MS-MARCO passage collection has around 500M to-ken mentions). COIL-full is able to capture match-ing patterns as effectively with exact match signalsfrom only query tokens’ mentions and a single CLSmatching to bridge the vocabulary gap.We observe a similar pattern in the rerank task.COIL-tok is already able to outperform dense re-triever and COIL-full further adds up to perfor-mance with CLS matching, being on-par with Col-BERT. Meanwhile, previous BERT rerankers havelittle performance advantage over COIL5. In prac-tice, we found BERT rerankers to be much more5Close performance between COIL and BERT rerankersis partially due to the bottleneck of BM25 candidates.Table 1: MSMARCO passage collection results. Results not applicable are denoted ‘–’ and no available ‘n.a.’.MS MARCO Passage RankingDev Rerank Dev Retrieval DL2019 RetrievalModel MRR@10 MRR@10 Recall@1K NDCG@10 MRR@1KLexical RetrieverBM25 – 0.184 0.853 0.506 0.825DeepCT – 0.243 0.909 0.572 0.883DocT5Query – 0.278 0.945 0.642 0.888BM25+BERT reranker 0.347 – – – –Dense RetrieverDense (BM25 neg) n.a. 0.299 0.928 0.600 n.a.Dense (rand + BM25 neg) n.a. 0.311 0.952 0.576 n.a.Dense (our train) 0.312 0.304 0.932 0.635 0.898ColBERT 0.349 0.360 0.968 n.a. n.a.COIL-tok 0.336 0.341 0.949 0.660 0.915COIL-full 0.348 0.355 0.963 0.704 0.924Table 2: MSMARCO document collection results. Results not applicable are denoted ‘–’ and no available ‘n.a.’.MS MARCO Document RankingDev Rerank Dev Retrieval DL2019 RetrievalModel MRR@10 MRR@10 Recall@1K NDCG@10 MRR@1KLexical RetrieverBM25 – 0.230 0.886 0.519 0.805DeepCT – 0.320 0.942 0.544 0.891DocT5Query – 0.288 0.926 0.597 0.837BM25+BERT reranker 0.383 – – – –Dense RetrieverDense (BM25 neg) n.a. 0.299 0.928 0.600 n.a.Dense (rand + BM25 neg) n.a. 0.311 0.952 0.576 n.a.Dense (our train) 0.358 0.340 0.883 0.546 0.785COIL-tok 0.381 0.385 0.952 0.626 0.921COIL-full 0.388 0.397 0.962 0.636 0.913expensive, requiring over 2700 ms for rerankingcompared to around 10ms in the case of COIL.Table 2 reports the results on MSMARCO docu-ment collection. In general, we observe a similarpattern as with the passage case. COIL systemssigniﬁcantly outperform both lexical and dense sys-tems in MRR and NDCG and retain a small advan-tage measured in recall. The results suggest thatCOIL can be applicable to longer documents witha consistent advantage in effectiveness.The results indicate exact lexical match mecha-nism can be greatly improved with the introductionof contextualized representation in COIL. COIL’stoken-level match also yields better ﬁne-grainedsignals than dense retriever’s global match signal.COIL-full further combines the lexical signals withdense CLS match, forming a system that can dealwith both vocabulary and semantic mismatch, be-ing as effective as all-to-all system.5.2 Analysis of DimensionalityThe second experiment tests how varying COIL’stoken dimension ntand CLS dimension ncaffectmodel effectiveness and efﬁciency. We record re-trieval performance and latency on MARCO pas-sage collection in Table 3.In COIL-full systems, reducing CLS dimensionfrom 768 to 128 leads to a small drop in perfor-mance on the Dev set, indicating that a full 768dimension may not be necessary for COIL. Keep-ing CLS dimension at 128, systems with tokendimension 32 and 8 have very small performancedifference, suggesting that token-speciﬁc semanticconsumes much fewer dimensions. Similar patterninntis also observed in COIL-tok ( nc= 0).On the DL2019 queries, we observe that reduc-ing dimension actually achieves better MRR. Webelieve this is due to a regulatory effect, as theTable 3: Performance and latency of COIL systems with different representation dimensions. Results not applica-ble are denoted ‘–’ and no available ‘n.a.’. Here ncdenotes COIL CLS dimension and nttoken vector dimension.*: ColBERT use approximate search and quantization. We exclude I/O time from measurements.Dev Retrieval DL2019 Retrieval Latency/msModel MRR@10 Recall@1K NDCG@10 MRR CPU GPUBM25 0.184 0.853 0.506 0.825 36 n.a.Dense 0.304 0.932 0.635 0.898 293 32ColBERT 0.360 0.968 n.a. n.a. 458* –COILncnt768 32 0.355 0.963 0.704 0.924 380 41128 32 0.350 0.953 0.692 0.956 125 23128 8 0.347 0.956 0.694 0.977 113 210 32 0.341 0.949 0.660 0.915 67 180 8 0.336 0.940 0.678 0.953 55 16Table 4: Sample query document pairs with similarity scores produced by COIL. Tokens in examination are coloredblue. Numbers in brackets are query-document vector similarities computed with vectors generated by COIL.Query Token COIL Contextualized Exact Match Score Relevancewhat is a cabinet in govtCabinet [16.28] (government) A cabinet [16.75] is a body of high-ranking state ofﬁcials, typically consisting of the top leaders of the ....+Cabinet [7.23] is 20x60 and top is 28x72. .... I had a 2cm granite counter-top installed with a 10 inch overhang on one side and a 14 inch....-what is priority passPriority Pass [11.61] is an independent airport lounge access program. Amembership provides you with access to their network of over 700 ....+Snoqualmie Pass [7.98] is a mountain pass [6.83] that carries Interstate90 through the Cascade Range in the U.S. State of Washington....-what isnjstartNJSTART is [1.25] a self-service online platform that allows vendors tomanage forms, certiﬁcations, submit proposals, access training ....+Contract awardees will receive their Blanket P.O. once it is [-0.10] con-verted, and details regarding that process will also be sent...-test queries were labeled differently from the MS-MARCO train/dev queries (Craswell et al., 2020).We also record CPU and GPU search latencyin Table 3. Lowering COIL-full’s CLS dimen-sion from 768 to 128 gives a big speedup, makingCOIL faster than DPR system. Further droppingtoken dimensions provide some extra speedup. TheCOIL-tok systems run faster than COIL-full, with alatency of the same order of magnitude as the tradi-tional BM25 system. Importantly, lower dimensionCOIL systems still retain a performance advantageover dense systems while being much faster. Weinclude ColBERT’s latency reported in the originalpaper, which was optimized by approximate searchand quantization. All COIL systems have lowerlatency than ColBERT even though our current im-plementation does not use those optimization tech-niques. We however note that approximate searchand quantization are applicable to COIL, and leavethe study of speeding up COIL to future work.5.3 Case StudyCOIL differs from all previous embedding-basedmodels in that it does not use a single uniﬁed em-bedding space. Instead, for a speciﬁc token, COILlearns an embedding space to encode and measurethe semantic similarity of the token in differentcontexts. In this section, we show examples whereCOIL differentiates different senses of a word un-der different contexts. In Table 4, we show howthe token similarity scores differ across contexts inrelevant and irrelevant query document pairs.The ﬁrst query looks for “cabinet” in the contextof “govt” (abbreviation for “government”). Thetwo documents both include query token "cabinet"but of a different concept. The ﬁrst one refers tothe government cabinet and the second to a caseor cupboard. COIL manages to match “cabinet” inthe query to “cabinet” in the ﬁrst document witha much higher score. In the second query, "pass"in both documents refer to the concept of permis-sion. However, through contextualization, COILcaptures the variation of the same concept and as-signs a higher score to “pass” in the ﬁrst document.Stop words like “it”, “a”, and “the” are com-monly removed in classic exact match IR systemsas they are not informative on their own. In thethird query, on the other hand, we observe thatCOIL is able to differentiate “is” in an explanatorysentence and “is” in a passive form, assigning theﬁrst higher score to match query context.All examples here show that COIL can go be-yond matching token surface form and introducerich context information to estimate matching. Dif-ferences in similarity scores across mentions underdifferent contexts demonstrate how COIL systemsgain strength over lexical systems.6 Conclusion and Future WorkExact lexical match systems have been widely usedfor decades in classical IR systems and prove to beeffective and efﬁcient. In this paper, we point outa critical problem, semantic mismatch, that gener-ally limits all IR systems based on surface tokenfor matching. To ﬁx semantic mismatch, we in-troduce contextualized exact match to differentiatethe same token in different contexts, providing ef-fective semantic-aware token match signals. Wefurther propose contextualized inverted list (COIL)search index which swaps token statistics in in-verted lists with contextualized vector representa-tions to perform effective search.On two large-scale ad hoc retrieval benchmarks,we ﬁnd COIL substantially improves lexical re-trieval and outperforms state-of-the-art dense re-trieval systems. These results indicate large head-room of the simple-but-efﬁcient exact lexical matchscheme. When the introduction of contextualiza-tion handles the issue of semantic mismatch, exactmatch system gains the capability of modeling com-plicated matching patterns that were not capturedby classical systems.V ocabulary mismatch in COIL can also belargely mitigated with a high-level CLS vectormatching. The full system performs on par withmore expensive and complex all-to-all match re-trievers. The success of the full system also showsthat dense retrieval and COIL’s exact token match-ing give complementary effects, with COIL makingup dense system’s lost token level matching signalsand dense solving the vocabulary mismatch proba-bly for COIL.With our COIL systems showing viable searchlatency, we believe this paper makes a solid steptowards building next-generation index that storessemantics. At the intersection of lexical and neuralsystems, efﬁcient algorithms proposed for both canpush COIL towards real-world systems.ReferencesS. Blackford, J. Demmel, J. Dongarra, I. Duff, S. Ham-marling, Greg Henry, M. Héroux, L. Kaufman, An-drew Lumsdaine, A. Petitet, R. Pozo, K. Remington,and C. Whaley. 2002. An updated set of basic linearalgebra subprograms (blas). ACM Transactions onMathematical Software , 28.Nick Craswell, Bhaskar Mitra, Emine Yilmaz, DanielCampos, and Ellen M V oorhees. 2020. Overviewof the trec 2019 deep learning track. arXiv preprintarXiv:2003.07820 .Zhuyun Dai and J. Callan. 2019a. Context-aware sen-tence/passage term importance estimation for ﬁrststage retrieval. ArXiv , abs/1910.10687.Zhuyun Dai and J. Callan. 2020. Context-aware docu-ment term weighting for ad-hoc search. Proceedingsof The Web Conference 2020 .Zhuyun Dai and Jamie Callan. 2019b. Deeper text un-derstanding for IR with contextual neural languagemodeling. In Proceedings of the 42nd InternationalACM SIGIR Conference on Research and Develop-ment in Information Retrieval, SIGIR 2019, Paris,France, July 21-25, 2019 , pages 985–988. ACM.J. Devlin, Ming-Wei Chang, Kenton Lee, and KristinaToutanova. 2019. Bert: Pre-training of deep bidirec-tional transformers for language understanding. InNAACL-HLT .Fernando Diaz, Bhaskar Mitra, and Nick Craswell.2016. Query expansion with locally-trained wordembeddings. In Proceedings of the 54th AnnualMeeting of the Association for Computational Lin-guistics .Debasis Ganguly, Dwaipayan Roy, Mandar Mitra,and Gareth J. F. Jones. 2015. Word embeddingbased generalized language model for informationretrieval. In Proceedings of the 38th InternationalACM SIGIR Conference on Research and Develop-ment in Information Retrieval .Luyu Gao, Zhuyun Dai, and Jamie Callan. 2020. Mod-ularized transfomer-based ranking framework. InProceedings of the 2020 Conference on EmpiricalMethods in Natural Language Processing, EMNLP2020, Online, November 16-20, 2020 . Associationfor Computational Linguistics.Luyu Gao, Zhuyun Dai, and Jamie Callan. 2021a. Re-think training of BERT rerankers in multi-stage re-trieval pipeline. In Advances in Information Re-trieval - 43rd European Conference on IR Research,ECIR 2021, Virtual Event, March 28 - April 1, 2021,Proceedings, Part II .Luyu Gao, Zhuyun Dai, Tongfei Chen, Zhen Fan, Ben-jamin Van Durme, and Jamie Callan. 2021b. Com-plement lexical retrieval model with semantic resid-ual embeddings. In Advances in Information Re-trieval - 43rd European Conference on IR Research,ECIR 2021, Virtual Event, March 28 - April 1, 2021,Proceedings, Part I .J. Guo, Y . Fan, Qingyao Ai, and W. Croft. 2016. Adeep relevance matching model for ad-hoc retrieval.Proceedings of the 25th ACM International on Con-ference on Information and Knowledge Manage-ment .R. Guo, Philip Y . Sun, E. Lindgren, Quan Geng, DavidSimcha, Felix Chern, and S. Kumar. 2019. Accel-erating large-scale inference with anisotropic vectorquantization. arXiv: Learning .Charles R. Harris, K. Jarrod Millman, Stéfan Jvan der Walt, Ralf Gommers, Pauli Virtanen, DavidCournapeau, Eric Wieser, Julian Taylor, Sebas-tian Berg, Nathaniel J. Smith, Robert Kern, MattiPicus, Stephan Hoyer, Marten H. van Kerkwijk,Matthew Brett, Allan Haldane, Jaime Fernández delRío, Mark Wiebe, Pearu Peterson, Pierre Gérard-Marchant, Kevin Sheppard, Tyler Reddy, WarrenWeckesser, Hameer Abbasi, Christoph Gohlke, andTravis E. Oliphant. 2020. Array programming withNumPy. Nature .Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng,Alex Acero, and Larry Heck. 2013. Learning deepstructured semantic models for web search usingclickthrough data. In Proceedings of the 22nd ACMinternational conference on Information & Knowl-edge Management .Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux,and J. Weston. 2020. Poly-encoders: Architec-tures and pre-training strategies for fast and accuratemulti-sentence scoring. In ICLR .J. Johnson, M. Douze, and H. Jégou. 2017. Billion-scale similarity search with gpus. ArXiv ,abs/1702.08734.V . Karpukhin, Barlas O ˘guz, Sewon Min, PatrickLewis, Ledell Yu Wu, Sergey Edunov, DanqiChen, and W. Yih. 2020. Dense passage re-trieval for open-domain question answering. ArXiv ,abs/2004.04906.O. Khattab and M. Zaharia. 2020. Colbert: Efﬁcientand effective passage search via contextualized lateinteraction over bert. Proceedings of the 43rd Inter-national ACM SIGIR Conference on Research andDevelopment in Information Retrieval .Yoon Kim. 2014. Convolutional neural networks forsentence classiﬁcation. In EMNLP .John Lafferty and Chengxiang Zhai. 2001. Documentlanguage models, query models, and risk minimiza-tion for information retrieval. In Proceedings of the24th Annual International ACM SIGIR Conferenceon Research and Development in Information Re-trieval .Victor Lavrenko and W. Bruce Croft. 2001. Relevance-based language models. In Proceedings of the 24thAnnual International ACM SIGIR Conference on Re-search and Development in Information Retrieval .Y . Liu, Myle Ott, Naman Goyal, Jingfei Du, MandarJoshi, Danqi Chen, Omer Levy, M. Lewis, LukeZettlemoyer, and Veselin Stoyanov. 2019. Roberta:A robustly optimized bert pretraining approach.ArXiv , abs/1907.11692.Yi Luan, Jacob Eisenstein, Kristina Toutanova, andM. Collins. 2020. Sparse, dense, and atten-tional representations for text retrieval. ArXiv ,abs/2005.00181.Sean MacAvaney, F. Nardini, R. Perego, N. Tonellotto,Nazli Goharian, and O. Frieder. 2020. Efﬁcient doc-ument re-ranking for transformers by precomputingterm representations. Proceedings of the 43rd Inter-national ACM SIGIR Conference on Research andDevelopment in Information Retrieval .Donald Metzler and W. Bruce Croft. 2005. A markovrandom ﬁeld model for term dependencies. In SIGIR2005: Proceedings of the 28th Annual InternationalACM SIGIR Conference on Research and Develop-ment in Information Retrieval .Tomas Mikolov, Ilya Sutskever, Kai Chen, G. S. Cor-rado, and J. Dean. 2013. Distributed representationsof words and phrases and their compositionality. InNIPS .Rodrigo Nogueira and Kyunghyun Cho. 2019. Passagere-ranking with bert. ArXiv , abs/1901.04085.Rodrigo Nogueira and Jimmy Lin. 2019. Fromdoc2query to doctttttquery.Adam Paszke, Sam Gross, Francisco Massa, AdamLerer, James Bradbury, Gregory Chanan, TrevorKilleen, Zeming Lin, Natalia Gimelshein, LucaAntiga, Alban Desmaison, Andreas Kopf, EdwardYang, Zachary DeVito, Martin Raison, Alykhan Te-jani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,Junjie Bai, and Soumith Chintala. 2019. Py-torch: An imperative style, high-performance deeplearning library. In H. Wallach, H. Larochelle,A. Beygelzimer, F. d'Alché-Buc, E. Fox, and R. Gar-nett, editors, Advances in Neural Information Pro-cessing Systems 32 . Curran Associates, Inc.Jeffrey Pennington, R. Socher, and Christopher D.Manning. 2014. Glove: Global vectors for word rep-resentation. In EMNLP .Matthew E. Peters, Mark Neumann, Mohit Iyyer, MattGardner, Christopher Clark, Kenton Lee, and LukeZettlemoyer. 2018. Deep contextualized word repre-sentations. ArXiv , abs/1802.05365.Stephen E Robertson and Steve Walker. 1994. Somesimple effective approximations to the 2-poissonmodel for probabilistic weighted retrieval. In Pro-ceedings of the 17th Annual International ACM-SIGIR Conference on Research and Development inInformation Retrieval .Ashish Vaswani, Noam Shazeer, Niki Parmar, JakobUszkoreit, Llion Jones, Aidan N. Gomez, L. Kaiser,and Illia Polosukhin. 2017. Attention is all you need.InNIPS .Thomas Wolf, Lysandre Debut, Victor Sanh, JulienChaumond, Clement Delangue, Anthony Moi, Pier-ric Cistac, Tim Rault, Rémi Louf, Morgan Funtow-icz, Joe Davison, Sam Shleifer, Patrick von Platen,Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,Teven Le Scao, Sylvain Gugger, Mariama Drame,Quentin Lhoest, and Alexander M. Rush. 2019.Huggingface’s transformers: State-of-the-art naturallanguage processing. ArXiv , abs/1910.03771.Chenyan Xiong, Zhuyun Dai, J. Callan, Zhiyuan Liu,and R. Power. 2017. End-to-end neural ad-hoc rank-ing with kernel pooling. Proceedings of the 40thInternational ACM SIGIR Conference on Researchand Development in Information Retrieval .Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,J. Liu, P. Bennett, Junaid Ahmed, and Arnold Over-wijk. 2020. Approximate nearest neighbor negativecontrastive learning for dense text retrieval. ArXiv ,abs/2007.00808.Z. Yang, Zihang Dai, Yiming Yang, J. Carbonell,R. Salakhutdinov, and Quoc V . Le. 2019. Xlnet:Generalized autoregressive pretraining for languageunderstanding. In NeurIPS .A AppendixA.1 Index Building IllustrationThe following ﬁgure demonstrates how the document "apple pie baked ..." is indexed by COIL. Thedocument is ﬁrst processed by a ﬁne-tuned deep LM to produce for each token a contextualized vector.The vectors of each term "apple" and "juice" are collected to the corresponding inverted list index alongwith the document id for lookup.appleLMuapplevappleDocument #10 - apple pie baked ...10vpie10uvpie bakedvpie wbakedv10wbakedFigure 4: COIL Index Building of document "apple pie baked..."A.2 Search IllustrationThe following ﬁgure demonstrates how the query "apple juice" is processed by COIL. Contextualizedvectors of each term "apple" and "juice" go to the corresponding inverted list index consisting of a lookupid array and a matrix stacked from document term vectors. For each index, a matrix vector product is runto produce an array of scores. Afterwards a max-scatter of scores followed by a sortproduces the ﬁnalranking. Note for each index, we show only operations for a subset of vectors (3 vectors) in the indexmatrix.v u776zyx776ScoreIdxzyx ScoreIndexapplev w975rqp975ScoreIdxrqp ScoreIndexjuiceSortMatrix V ector ProductMax ScatterSortingQuery: apple juiceFigure 5: COIL Search of query "apple juice".