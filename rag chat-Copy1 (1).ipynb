{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f57b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import openai\n",
    "from llama_index import VectorStoreIndex\n",
    "import PyPDF2\n",
    "from io import BytesIO\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cceb59f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aea61a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e136c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61cac2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_urls = [\n",
    "    \"https://dl.acm.org/doi/pdf/10.1145/3397271.3401075\",\n",
    "    \"https://arxiv.org/pdf/2104.07186.pdf\",\n",
    "    \"https://arxiv.org/pdf/2106.14807.pdf\",\n",
    "    \"https://arxiv.org/pdf/2301.03266.pdf\",\n",
    "    \"https://arxiv.org/pdf/2303.07678.pdf\"\n",
    "]\n",
    "\n",
    "def download_pdf(url):\n",
    "    response = requests.get(url)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da61a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c09f71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ai\\\\vectorstoreindex'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd()\n",
    "data_path = os.path.join(path,\"parsed_documents\")\n",
    "index_path = os.path.join(path,\"vectorstoreindex\")\n",
    "data_path\n",
    "index_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44848469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'd:\\ai\\parsed_documents' created successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    os.makedirs(index_path, exist_ok=True)\n",
    "    print(f\"Directory '{data_path}' created successfully.\")\n",
    "except FileExistsError:\n",
    "    print(f\"Directory '{data_path}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdb4b998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and parsing Paper 1...\n",
      "Downloading and parsing Paper 2...\n",
      "Downloading and parsing Paper 3...\n",
      "Downloading and parsing Paper 4...\n",
      "Downloading and parsing Paper 5...\n"
     ]
    }
   ],
   "source": [
    "for idx, url in enumerate(paper_urls):\n",
    "    print(f\"Downloading and parsing Paper {idx+1}...\")\n",
    "    pdf_content = download_pdf(url)\n",
    "    pdf_file = BytesIO(pdf_content)\n",
    "    reader = PyPDF2.PdfReader(pdf_file)\n",
    "    text = ''\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    text = text.replace(\"\\n\",\"\")\n",
    "    file_name = f\"paper_{idx+1}.txt\"\n",
    "    file_path = os.path.join(data_path, file_name)\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f08537c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11fd2147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index import load_index_from_storage,StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fdc0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4edb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf8a84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd950d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.storage_context.persist(index_path)\n",
    "storage_context = StorageContext.from_defaults(persist_dir=index_path)\n",
    "loaded_index = load_index_from_storage(storage_context)\n",
    "query_engine = loaded_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c45c10af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10fbe4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The architecture of ColBERT comprises a query encoder ğ‘“ğ‘„, a document encoder ğ‘“ğ·, and a late interaction mechanism. The query encoder ğ‘“ğ‘„ encodes a query ğ‘ into a bag of fixed-size embeddings ğ¸ğ‘, while the document encoder ğ‘“ğ· encodes a document ğ‘‘ into another bag ğ¸ğ‘‘. The late interaction mechanism computes the relevance score between ğ‘ and ğ‘‘ via a summation of maximum similarity (MaxSim) operators. The query and document encoders are based on BERT, and the query encoder is augmented with a special token [Q] prepended to the query.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"architecture of  ColBERT\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8af987a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    # Generate a response using GPT-3.5 and the retrieved vectors\n",
    "    response = query_engine.query(prompt)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded73396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: architecture of ColBERT\n",
      "AI: \n",
      "The architecture of ColBERT comprises a query encoder ğ‘“ğ‘„, a document encoder ğ‘“ğ·, and a late interaction mechanism. The query encoder ğ‘“ğ‘„ encodes a query ğ‘ into a bag of fixed-size embeddings ğ¸ğ‘, while the document encoder ğ‘“ğ· encodes a document ğ‘‘ into another bag ğ¸ğ‘‘. The late interaction mechanism computes the relevance score between ğ‘ and ğ‘‘ via a summation of maximum similarity (MaxSim) operators.\n",
      "User: explain it elaborately\n",
      "AI: \n",
      "In this paper, the authors explore a technique to improve the effectiveness and efficiency of Doc2Query by filtering out queries that do not reflect the original passage. This approach, called Doc2Query-- (Doc2Query-minus-minus), uses existing neural relevance models to identify and remove poor queries prior to indexing. Through experimentation on the MS MARCO dataset, the authors find that their filtering approach can improve the retrieval effectiveness of indexes built using Doc2Query-- by up to 16%. Additionally, filtering naturally reduces the index size, lowering storage and query-time computational costs. Finally, the authors explore the index-time overheads introduced by the filtering process and conclude that the gains from filtering more than make up for the additional time spent generating more queries. The approach also has a positive impact on the environmental costs of applying Doc2Query; the same retrieval effectiveness can be achieved with only about a third of the computational cost when indexing.\n",
      "User: summarize the paper\n",
      "AI: \n",
      "This paper presents a technique to improve the effectiveness and efficiency of Doc2Query by filtering out queries that do not reflect the original passage. The approach uses existing neural relevance models to identify poor queries and remove them prior to indexing. Through experimentation on the MS MARCO dataset, the authors find that their filtering approach can improve the retrieval effectiveness of indexes built using Doc2Query by up to 16%. Additionally, the approach reduces the index size, lowering storage and query-time computational costs. Finally, the authors explore the index-time overheads introduced by the filtering process and conclude that the gains from filtering more than make up for the additional time spent generating more queries.\n",
      "User: what is doc2query\n",
      "AI: \n",
      "No, doc2query is not mentioned in the context information.\n",
      "User: tell about the Doc2Query\n",
      "AI: \n",
      "Doc2Query is a sequence-to-sequence model that maps a document to queries that it might be able to answer. By appending these generated queries to a documentâ€™s content before indexing, the document is more likely to be retrieved for user queries when using a model like BM25.\n",
      "User: what is a sequence to sequence model\n",
      "AI: \n",
      "Yes, a sequence-to-sequence model is mentioned in the context information. Doc2Query is an approach that trains a sequence-to-sequence model (e.g., T5 [33]) to predict queries that may be relevant to a particular text.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    prompt = user_input[5:]\n",
    "    response = generate_response(prompt)\n",
    "    print(\"AI:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
